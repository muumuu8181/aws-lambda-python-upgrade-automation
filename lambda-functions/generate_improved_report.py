#!/usr/bin/env python3
"""æ”¹å–„ç‰ˆHTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ†ã‚¹ãƒˆ"""

import json
import sys
import os
from datetime import datetime

# monitoring_lambdaã‹ã‚‰é–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.append(os.path.dirname(__file__))
from monitoring_lambda import generate_html_report, get_component_type, get_file_type

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆæœ€æ–°å®Ÿè¡Œã®çµæœã‚’æ¨¡æ“¬ï¼‰
sample_summary = {
    "batch_id": "B20250827100",
    "status": "SUCCESS", 
    "started": "2025-08-27T14:00:34.867000+09:00",
    "ended": "2025-08-27T14:02:54.284000+09:00",
    "counts": {
        "input_files": 1,
        "input_rows": 10,
        "output_files": 1, 
        "output_rows": 10,
        "redshift_loaded": 20  # é‡è¤‡åˆ†ã‚‚å«ã‚€
    },
    "steps": [
        {
            "step": "prevalidate",
            "ok": True,
            "input": {"files_count": 1, "total_size_bytes": 714},
            "output": {"validated_files": 1, "errors": []},
            "note": "1ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãŒæ­£å¸¸å®Œäº†",
            "ts": "2025-08-27T14:00:40"
        },
        {
            "step": "glue_convert", 
            "ok": True,
            "input": {"s3": "s3://etl-observer-dev-landing/test/sample.csv", "rows": 10},
            "output": {"s3": "s3://etl-observer-dev-staging/parquet/employees/test/sample.csv", "rows": 10},
            "note": "CSVâ†’Parquetå¤‰æ›æˆåŠŸ: 10è¡Œâ†’10è¡Œ",
            "ts": "2025-08-27T14:01:45"
        },
        {
            "step": "redshift_load",
            "ok": True, 
            "input": {"s3": "s3://etl-observer-dev-staging/parquet/employees/test/sample.csv", "rows": 10},
            "output": {"rows": 20},
            "note": "Redshiftã«20è¡Œæ­£å¸¸ãƒ­ãƒ¼ãƒ‰å®Œäº† (æ—¢å­˜ãƒ‡ãƒ¼ã‚¿å«ã‚€)",
            "ts": "2025-08-27T14:02:30"
        },
        {
            "step": "finalize",
            "ok": True,
            "input": {"total_files": 1, "batch_id": "B20250827100"}, 
            "output": {"successful_conversions": 1, "successful_loads": 1},
            "note": "ãƒãƒƒãƒå‡¦ç†æ­£å¸¸çµ‚äº†: 1å¤‰æ›, 1ãƒ­ãƒ¼ãƒ‰, 0å¤±æ•—",
            "ts": "2025-08-27T14:02:54"
        }
    ],
    "failures": [],
    "generated_at": datetime.now().isoformat()
}

# è¤‡æ•°å®Ÿè¡Œãƒªã‚¹ãƒˆï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰
execution_list = [
    {
        "executionArn": "arn:aws:states:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT_ID:execution:sf-etl-observer-dev-ingest:bf983fbe-a93f-4c2b-a949-2b8ade4c7040",
        "startDate": "2025-08-27T14:00:34.867000+09:00", 
        "status": "SUCCEEDED",
        "current": True
    },
    {
        "executionArn": "arn:aws:states:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT_ID:execution:sf-etl-observer-dev-ingest:eb8ae983-4ffe-4cfc-9798-9ebeb3403eee",
        "startDate": "2025-08-27T11:08:55.983000+09:00",
        "status": "SUCCEEDED", 
        "current": False
    }
]

if __name__ == "__main__":
    print("ğŸš€ æ”¹å–„ç‰ˆHTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–‹å§‹...")
    
    # æ”¹å–„ç‰ˆHTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    html_content = generate_html_report(
        batch_id=sample_summary["batch_id"],
        summary=sample_summary,
        execution_list=execution_list
    )
    
    # HTMLãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    output_path = "improved_report.html"
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(html_content)
    
    print(f"âœ… æ”¹å–„ç‰ˆHTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {output_path}")
    print(f"ğŸ“Š ãƒãƒƒãƒID: {sample_summary['batch_id']}")
    print(f"ğŸ“ˆ å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—: {len(sample_summary['steps'])}å€‹")
    print(f"ğŸ”„ å®Ÿè¡Œå±¥æ­´: {len(execution_list)}ä»¶")
    
    # ãƒ–ãƒ©ã‚¦ã‚¶ã§é–‹ã
    print("\nğŸŒ ãƒ–ãƒ©ã‚¦ã‚¶ã§ç¢ºèª:")
    print(f"file:///{os.path.abspath(output_path).replace(os.sep, '/')}")